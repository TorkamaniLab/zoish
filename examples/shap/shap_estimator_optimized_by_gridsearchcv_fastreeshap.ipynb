{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -python (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -tatsmodels (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/TorkamaniLab/zoish.git\n",
      "  Cloning https://github.com/TorkamaniLab/zoish.git to /private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-req-build-sm2v71s6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TorkamaniLab/zoish.git /private/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/pip-req-build-sm2v71s6\n",
      "  Resolved https://github.com/TorkamaniLab/zoish.git to commit 31067e22eb3a79b4799bb7f2517f7dcb261e7d0e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle==2.2.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (2.2.1)\n",
      "Requirement already satisfied: fasttreeshap==0.1.6 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (0.1.6)\n",
      "Requirement already satisfied: importlib-metadata==6.7.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (6.7.0)\n",
      "Requirement already satisfied: joblib==1.3.2 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.3.2)\n",
      "Requirement already satisfied: llvmlite==0.39.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (0.39.1)\n",
      "Requirement already satisfied: numba==0.56.4 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (0.56.4)\n",
      "Requirement already satisfied: numpy==1.21.6 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.21.6)\n",
      "Requirement already satisfied: packaging==23.2 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (23.2)\n",
      "Requirement already satisfied: pandas==1.3.5 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.3.5)\n",
      "Requirement already satisfied: psutil==5.9.6 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (5.9.6)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (2.8.2)\n",
      "Requirement already satisfied: pytz==2023.4 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (2023.4)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.0.2)\n",
      "Requirement already satisfied: scipy==1.7.3 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.7.3)\n",
      "Requirement already satisfied: shap==0.42.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (0.42.1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (1.16.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (0.0.7)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (3.1.0)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (4.66.1)\n",
      "Requirement already satisfied: typing_extensions==4.7.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (4.7.1)\n",
      "Requirement already satisfied: zipp==3.15.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (3.15.0)\n",
      "Requirement already satisfied: matplotlib in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from zoish==5.0.3) (3.5.3)\n",
      "Requirement already satisfied: setuptools in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from numba==0.56.4->zoish==5.0.3) (68.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from matplotlib->zoish==5.0.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from matplotlib->zoish==5.0.3) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from matplotlib->zoish==5.0.3) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from matplotlib->zoish==5.0.3) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages (from matplotlib->zoish==5.0.3) (3.1.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -python (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -tatsmodels (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -python (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -tatsmodels (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting feature-engine\n",
      "  Using cached feature_engine-1.4.0-py2.py3-none-any.whl (276 kB)\n",
      "Collecting category-encoders\n",
      "  Using cached category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.0.2-cp37-cp37m-macosx_10_13_x86_64.whl (7.8 MB)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-1.6.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "Collecting scipy>=1.4.1 (from feature-engine)\n",
      "  Using cached scipy-1.7.3-cp37-cp37m-macosx_10_9_x86_64.whl (33.0 MB)\n",
      "Collecting statsmodels>=0.11.1 (from feature-engine)\n",
      "  Using cached statsmodels-0.13.5-cp37-cp37m-macosx_10_9_x86_64.whl (9.6 MB)\n",
      "Collecting patsy>=0.5.1 (from category-encoders)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting importlib-resources (from category-encoders)\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Using cached comm-0.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting ipython>=6.1.0 (from ipywidgets)\n",
      "  Using cached ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "Collecting traitlets>=4.3.1 (from ipywidgets)\n",
      "  Using cached traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas)\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Using cached pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting setuptools>=18.5 (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached setuptools-68.0.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting decorator (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting pickleshare (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pygments (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting backcall (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting matplotlib-inline (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting pexpect>4.3 (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting appnope (from ipython>=6.1.0->ipywidgets)\n",
      "  Using cached appnope-0.1.3-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting six (from patsy>=0.5.1->category-encoders)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting packaging>=21.3 (from statsmodels>=0.11.1->feature-engine)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources->category-encoders)\n",
      "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython>=6.1.0->ipywidgets)\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=6.1.0->ipywidgets)\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Using cached category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "Using cached ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "Using cached comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Using cached pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
      "Using cached widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "Using cached setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -python (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -tatsmodels (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/hjavedani/Documents/zoish/test_env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wcwidth, pytz, ptyprocess, pickleshare, backcall, appnope, zipp, widgetsnbextension, traitlets, threadpoolctl, six, setuptools, pygments, prompt-toolkit, pexpect, parso, packaging, numpy, jupyterlab-widgets, joblib, decorator, scipy, python-dateutil, patsy, matplotlib-inline, jedi, importlib-resources, comm, xgboost, scikit-learn, pandas, ipython, statsmodels, ipywidgets, feature-engine, category-encoders\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.13\n",
      "    Uninstalling wcwidth-0.2.13:\n",
      "      Successfully uninstalled wcwidth-0.2.13\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.4\n",
      "    Uninstalling pytz-2023.4:\n",
      "      Successfully uninstalled pytz-2023.4\n",
      "  Attempting uninstall: ptyprocess\n",
      "    Found existing installation: ptyprocess 0.7.0\n",
      "    Uninstalling ptyprocess-0.7.0:\n",
      "      Successfully uninstalled ptyprocess-0.7.0\n",
      "  Attempting uninstall: pickleshare\n",
      "    Found existing installation: pickleshare 0.7.5\n",
      "    Uninstalling pickleshare-0.7.5:\n",
      "      Successfully uninstalled pickleshare-0.7.5\n",
      "  Attempting uninstall: backcall\n",
      "    Found existing installation: backcall 0.2.0\n",
      "    Uninstalling backcall-0.2.0:\n",
      "      Successfully uninstalled backcall-0.2.0\n",
      "  Attempting uninstall: appnope\n",
      "    Found existing installation: appnope 0.1.3\n",
      "    Uninstalling appnope-0.1.3:\n",
      "      Successfully uninstalled appnope-0.1.3\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.15.0\n",
      "    Uninstalling zipp-3.15.0:\n",
      "      Successfully uninstalled zipp-3.15.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 4.0.9\n",
      "    Uninstalling widgetsnbextension-4.0.9:\n",
      "      Successfully uninstalled widgetsnbextension-4.0.9\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.9.0\n",
      "    Uninstalling traitlets-5.9.0:\n",
      "      Successfully uninstalled traitlets-5.9.0\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 68.0.0\n",
      "    Uninstalling setuptools-68.0.0:\n",
      "      Successfully uninstalled setuptools-68.0.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.17.2\n",
      "    Uninstalling Pygments-2.17.2:\n",
      "      Successfully uninstalled Pygments-2.17.2\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.43\n",
      "    Uninstalling prompt-toolkit-3.0.43:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.43\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.9.0\n",
      "    Uninstalling pexpect-4.9.0:\n",
      "      Successfully uninstalled pexpect-4.9.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.3\n",
      "    Uninstalling parso-0.8.3:\n",
      "      Successfully uninstalled parso-0.8.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab-widgets 3.0.9\n",
      "    Uninstalling jupyterlab-widgets-3.0.9:\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.9\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.3.2\n",
      "    Uninstalling joblib-1.3.2:\n",
      "      Successfully uninstalled joblib-1.3.2\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: patsy\n",
      "    Found existing installation: patsy 0.5.6\n",
      "    Uninstalling patsy-0.5.6:\n",
      "      Successfully uninstalled patsy-0.5.6\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.6\n",
      "    Uninstalling matplotlib-inline-0.1.6:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.6\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.1\n",
      "    Uninstalling jedi-0.19.1:\n",
      "      Successfully uninstalled jedi-0.19.1\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 5.12.0\n",
      "    Uninstalling importlib-resources-5.12.0:\n",
      "      Successfully uninstalled importlib-resources-5.12.0\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.4\n",
      "    Uninstalling comm-0.1.4:\n",
      "      Successfully uninstalled comm-0.1.4\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.6.2\n",
      "    Uninstalling xgboost-1.6.2:\n",
      "      Successfully uninstalled xgboost-1.6.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.34.0\n",
      "    Uninstalling ipython-7.34.0:\n",
      "      Successfully uninstalled ipython-7.34.0\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.13.5\n",
      "    Uninstalling statsmodels-0.13.5:\n",
      "      Successfully uninstalled statsmodels-0.13.5\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.1\n",
      "    Uninstalling ipywidgets-8.1.1:\n",
      "      Successfully uninstalled ipywidgets-8.1.1\n",
      "  Attempting uninstall: feature-engine\n",
      "    Found existing installation: feature-engine 1.4.0\n",
      "    Uninstalling feature-engine-1.4.0:\n",
      "      Successfully uninstalled feature-engine-1.4.0\n",
      "  Attempting uninstall: category-encoders\n",
      "    Found existing installation: category-encoders 2.6.3\n",
      "    Uninstalling category-encoders-2.6.3:\n",
      "      Successfully uninstalled category-encoders-2.6.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "zoish 5.0.3 requires pytz==2023.3.post1, but you have pytz 2023.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appnope-0.1.3 backcall-0.2.0 category-encoders-2.6.3 comm-0.1.4 decorator-5.1.1 feature-engine-1.4.0 importlib-resources-5.12.0 ipython-7.34.0 ipywidgets-8.1.1 jedi-0.19.1 joblib-1.3.2 jupyterlab-widgets-3.0.9 matplotlib-inline-0.1.6 numpy-1.21.6 packaging-23.2 pandas-1.3.5 parso-0.8.3 patsy-0.5.6 pexpect-4.9.0 pickleshare-0.7.5 prompt-toolkit-3.0.43 ptyprocess-0.7.0 pygments-2.17.2 python-dateutil-2.8.2 pytz-2023.4 scikit-learn-1.0.2 scipy-1.7.3 setuptools-68.0.0 six-1.16.0 statsmodels-0.13.5 threadpoolctl-3.1.0 traitlets-5.9.0 wcwidth-0.2.13 widgetsnbextension-4.0.9 xgboost-1.6.2 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/TorkamaniLab/zoish.git\n",
    "! pip install feature-engine category-encoders scikit-learn ipywidgets numpy pandas xgboost --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/xbcjnd1x5rn7ct1m_rnsblk80000gp/T/ipykernel_43665/1632922843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m  \u001b[0;31m# For accessing system-specific parameters and functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzoish\u001b[0m  \u001b[0;31m# Assuming it's a custom library for your project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m  \u001b[0;31m# For machine learning models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m  \u001b[0;31m# For gradient-boosted decision trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m  \u001b[0;31m# For numerical computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/zoish/test_env/lib/python3.7/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/zoish/test_env/lib/python3.7/site-packages/sklearn/__check_build/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_check_build\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_build\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mraise_build_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing built-in libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import sys  # For accessing system-specific parameters and functions\n",
    "import zoish  # Assuming it's a custom library for your project\n",
    "import sklearn  # For machine learning models\n",
    "import xgboost  # For gradient-boosted decision trees\n",
    "import numpy  # For numerical computations\n",
    "\n",
    "# Importing scikit-learn utilities for various ML tasks\n",
    "from sklearn.compose import ColumnTransformer  # For applying transformers to columns\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest classifier\n",
    "from sklearn.impute import SimpleImputer  # For handling missing data\n",
    "from sklearn.metrics import (  # For evaluating the model\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split  # For CV and splitting dataset\n",
    "from sklearn.pipeline import Pipeline  # For creating ML pipelines\n",
    "from sklearn.preprocessing import StandardScaler  # For feature scaling\n",
    "\n",
    "# Importing other third-party libraries\n",
    "from category_encoders import TargetEncoder  # For encoding categorical variables\n",
    "from xgboost import XGBClassifier  # XGBoost classifier\n",
    "from zoish.feature_selectors.shap_selectors import (  # For feature selection and visualization\n",
    "    ShapFeatureSelector,\n",
    "    ShapPlotFeatures,\n",
    ")\n",
    "import logging  # For logging events and errors\n",
    "\n",
    "# Configuring logging settings\n",
    "from zoish import logger  # Assuming it's a custom logger from zoish\n",
    "logger.setLevel(logging.ERROR)  # Set logging level to ERROR\n",
    "\n",
    "# Importing feature imputation library\n",
    "from feature_engine.imputation import MeanMedianImputer  # For imputing mean/median\n",
    "\n",
    "# Re-setting logging level (this seems redundant, consider keeping only one)\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Printing versions of key libraries for debugging and documentation\n",
    "print(f'Python version : {sys.version}')\n",
    "print(f'zoish version : {zoish.__version__}')\n",
    "print(f'sklearn version : {sklearn.__version__}')\n",
    "print(f'pandas version : {pd.__version__}')  # Using the alias for pandas\n",
    "print(f'numpy version : {numpy.__version__}')\n",
    "print(f'xgboost version : {xgboost.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Audiology (Standardized) Data Set\n",
    "###### https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\n",
    "\n",
    "\n",
    "#### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata = \"https://archive.ics.uci.edu/ml/machine-learning-databases/lymphography/lymphography.data\"\n",
    "urlname = \"https://archive.ics.uci.edu/ml/machine-learning-databases/lung-cancer/lung-cancer.names\"\n",
    "# column names\n",
    "col_names = [\n",
    "    \"class\",\n",
    "    \"lymphatics\",\n",
    "    \"block of affere\",\n",
    "    \"bl. of lymph. c\",\n",
    "    \"bl. of lymph. s\",\n",
    "    \"by pass\",\n",
    "    \"extravasates\",\n",
    "    \"regeneration of\",\n",
    "    \"early uptake in\",\n",
    "    \"lym.nodes dimin\",\n",
    "    \"lym.nodes enlar\",\n",
    "    \"changes in lym.\",\n",
    "    \"defect in node\",\n",
    "    \"changes in node\",\n",
    "    \"special forms\",\n",
    "    \"dislocation of\",\n",
    "    \"exclusion of no\",\n",
    "    \"no. of nodes in\",\n",
    "\n",
    "]\n",
    "\n",
    "data = pd.read_csv(urldata,names=col_names)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define labels and train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.loc[(data[\"class\"] == 1) | (data[\"class\"] == 2), \"class\"] = 0\n",
    "data.loc[data[\"class\"] == 3, \"class\"] = 1\n",
    "data.loc[data[\"class\"] == 4, \"class\"] = 2\n",
    "data[\"class\"] = data[\"class\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != \"class\"]\n",
    "y = data.loc[:, data.columns == \"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33,  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the feature pipeline steps:\n",
    "Here, we use an untuned XGBClassifier model with the ShapFeatureSelector.In the next section, we will repeat the same process but with a tuned XGBClassifier. The aim is to demonstrate that a better estimator can yield improved results when used with the ShapFeatureSelector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_for_feature_selector= XGBClassifier()     \n",
    "estimator_for_feature_selector.fit(X_train, y_train)\n",
    "# use fasttreeshap algorithm by setting use_faster_algorithm=True\n",
    "# also use its arguments as a kwargs\n",
    "\n",
    "shap_tree_explainer_kwargs={\n",
    "\"random_state\": 42,\n",
    "\"algorithm\": \"sampling\",\n",
    "\"linearize_link\":True,\n",
    "} \n",
    "shap_feature_selector = ShapFeatureSelector(model=estimator_for_feature_selector,use_faster_algorithm=True, shap_tree_explainer_kwargs=shap_tree_explainer_kwargs,num_features=5, scoring='accuracy',cv = 5, n_iter=10, direction='maximum')        \n",
    "# Define pre-processing for numeric columns (float and integer types)\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define pre-processing for categorical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', TargetEncoder(handle_missing='return_nan'))])\n",
    "\n",
    "# Combine preprocessing into one column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Feature Selection using ShapSelector \n",
    "feature_selection = shap_feature_selector \n",
    "\n",
    "# Classifier model\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Create a pipeline that combines the preprocessor with a feature selection and a classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('feature_selection', feature_selection),\n",
    "                           ('classifier', classifier)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Output first 10 predictions\n",
    "print(y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check performance of the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"F1 score : \")\n",
    "print(f1_score(y_test, y_test_pred,average='micro'))\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion matrix : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Use better estimator:\n",
    "In this iteration, we will utilize the optimally tuned estimator with the ShapFeatureSelector, which is expected to yield improved results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols =  X_train.select_dtypes(include=['int']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the XGBClassifier\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for XGBClassifier\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [ 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Define the scoring function\n",
    "scoring = make_scorer(f1_score, average='micro')  # Use 'micro' average in case of multiclass target\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid, cv=5, scoring=scoring, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Fit the GridSearchCV object\n",
    "estimator_for_feature_selector= grid_search.best_estimator_ \n",
    "# use fasttreeshap algorithm by setting use_faster_algorithm=True\n",
    "# also use its arguments as a kwargs\n",
    "\n",
    "shap_tree_explainer_kwargs={\n",
    "\"random_state\": 42,\n",
    "\"algorithm\": \"sampling\",\n",
    "\"linearize_link\":True,\n",
    "} \n",
    "shap_feature_selector = ShapFeatureSelector(model=estimator_for_feature_selector,use_faster_algorithm=True, shap_tree_explainer_kwargs=shap_tree_explainer_kwargs,num_features=5, scoring='accuracy',cv = 5, n_iter=10, direction='maximum')\n",
    "\n",
    "\n",
    "pipeline =Pipeline([\n",
    "            # int missing values imputers\n",
    "            ('floatimputer', MeanMedianImputer(\n",
    "                imputation_method='mean', variables=int_cols)),\n",
    "           \n",
    "            ('shap_feature_selector', shap_feature_selector),\n",
    "            ('classfier', RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "\n",
    " ])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Output first 10 predictions\n",
    "print(y_test_pred[:10])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance has improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"F1 score : \")\n",
    "print(f1_score(y_test, y_test_pred,average='micro'))\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion matrix : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap related plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the feature importance\n",
    "plot_factory = ShapPlotFeatures(shap_feature_selector) \n",
    "plot_factory.summary_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factory.summary_plot_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the feature importance\n",
    "plot_factory.bar_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factory.bar_plot_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factory.dependence_plot('special forms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of features\n",
    "X_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.17 ('prod_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3e82f33fff0f86e33d8c3a2efbacef89e166d1ae679c5c81a5bfe456b45cdcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
